{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xjhan\\miniconda3\\envs\\GroundLinkSubmission\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = {\n",
    "    \"s001\" : \"S1\",\n",
    "    \"s002\" : \"S2\",\n",
    "    \"s003\" : \"S3\",\n",
    "    \"s004\" : \"S4\",\n",
    "    \"s005\" : \"S5\",\n",
    "    \"s006\" : \"S6\",\n",
    "    \"s007\" : \"S7\",\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'Windows'\n",
    "# system = 'Ubuntu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "motiontype = {\n",
    "    'tree' : 'yoga',\n",
    "    'treearms' : 'yoga',\n",
    "    'chair' : 'yoga',\n",
    "    'squat' : 'yoga',\n",
    "    'worrier1' : 'warrior',\n",
    "    'worrier2' : 'warrior',\n",
    "    'sidestretch' : 'side_stretch',\n",
    "    'dog' : 'hand',\n",
    "    'jumpingjack' : 'jump',\n",
    "    'walk' : 'walk',\n",
    "    'walk_00': 'walk',\n",
    "    'hopping' : 'hopping',\n",
    "    'ballethighleg' : 'ballet_high',\n",
    "    'balletsmalljump' : 'ballet_jump',\n",
    "    'whirl' : 'dance',\n",
    "    'lambadadance' : 'yoga',\n",
    "    'taichi' : 'taichi',\n",
    "    'step' : 'stairs',\n",
    "    'tennisserve' : 'tennis',\n",
    "    'tennisgroundstroke' : 'tennis',\n",
    "    'soccerkick' : 'kicking',\n",
    "    'idling' : 'idling',\n",
    "    'idling_00' : 'idling',\n",
    "    'static' : 'static',\n",
    "    'ballet_high_leg' : 'ballet_high'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "\n",
    "def parse_motion_force(sourcemotion, contactdata, outputfile):\n",
    "    if os.path.exists(outputfile):\n",
    "        print(\"File exists.. Skipping..\")\n",
    "        pass\n",
    "\n",
    "    # load motion\n",
    "    moshpp = np.load(sourcemotion, allow_pickle=True)\n",
    "    # load force\n",
    "    force_data = np.load(contactdata, allow_pickle=True)\n",
    "    mocap = {}\n",
    "    num_joints = 55\n",
    "    num_body_joints = 22\n",
    "    mocap[\"gender\"] = moshpp[\"gender\"]\n",
    "\n",
    "    # load model file to remove pelvis offset from SMPL-X model\n",
    "    modelpath = '../Data/smplx/' + str(mocap[\"gender\"])\n",
    "    # modelpath = '../../../Data/QTM_SOMA_MOSH/support_files/smplx/' + str(mocap[\"gender\"])\n",
    "    modelfile = os.path.join(modelpath, 'model.npz')\n",
    "    modeldata = np.load(modelfile, allow_pickle=True)\n",
    "    pelvis_offset = modeldata['J'][0]\n",
    "\n",
    "    num_frames = min(len(moshpp['poses']), len(force_data.item()[\"CoP\"]))\n",
    "    mocap[\"angles\"] = torch.reshape(torch.tensor(moshpp[\"poses\"]), (len(moshpp['poses']), num_joints, 3))[:num_frames,:num_body_joints,:]\n",
    "    # mocap[\"angles\"] = torch.index_select(mocap[\"angles\"], 2, torch.LongTensor([0,2,1]))\n",
    "    \n",
    "    mocap[\"trans\"] = torch.tensor(moshpp[\"trans\"]).unsqueeze(1)[:num_frames]+pelvis_offset\n",
    "    # mocap[\"trans\"] = torch.index_select(mocap[\"trans\"], 2, torch.LongTensor([0,2,1]))\n",
    "    mocap[\"shape\"] = torch.tensor(moshpp[\"betas\"]).unsqueeze(1).repeat(num_frames, 1, 3)\n",
    "    mocap[\"framerate\"] = float(moshpp[\"mocap_framerate\"])\n",
    "    \n",
    "    contact = {}\n",
    "\n",
    "    COP = force_data.item()[\"CoP\"][:num_frames]\n",
    "    GRF = force_data.item()[\"GRF\"][:num_frames]\n",
    "\n",
    "    rotate_z = mocap[\"angles\"][:,0].clone()\n",
    "    rotate = torch.zeros(num_frames, 3)\n",
    "    rotate[:,2] = rotate_z[:,2]\n",
    "    pelvis_rot = torch.tensor(Rotation.from_rotvec(rotate.numpy()).as_matrix())\n",
    "    pelvis_t_project = mocap[\"trans\"].clone()\n",
    "    pelvis_t_project[:,:,2] = 0.0\n",
    "\n",
    "    transformation_mat = torch.eye(4).unsqueeze(0).repeat(num_frames, 1, 1)\n",
    "\n",
    "\n",
    "    transformation_mat[:, :3, :3] = pelvis_rot\n",
    "    mocap[\"to_global_rot\"] = pelvis_rot\n",
    "    rotation_mat_inv = torch.inverse(mocap[\"to_global_rot\"])\n",
    "    transformation_mat[:, :3, 3] = pelvis_t_project.squeeze(1)\n",
    "    mocap[\"to_global\"] = transformation_mat # double tensor\n",
    "\n",
    "\n",
    "    transformation_mat_inv = torch.inverse(transformation_mat)\n",
    "\n",
    "\n",
    "    homo = torch.ones(num_frames, 2, 1)\n",
    "    homo_COP = torch.cat((COP, homo), dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "    CoP_local = torch.matmul(transformation_mat_inv, homo_COP.transpose(-1, -2)).transpose(-1, -2)\n",
    "    # GRF_local = torch.matmul(rotation_mat_inv, GRF.type('torch.DoubleTensor').transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "    # shift CoP to projected pelvis\n",
    "    contact[\"CoP\"] = CoP_local[:, :, :-1].type('torch.FloatTensor')\n",
    "    contact[\"GRF\"] = GRF.type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "    homo_pelvis_one = torch.ones(num_frames, 1, 1)\n",
    "    homo_pelvis = torch.cat((mocap[\"trans\"], homo_pelvis_one), dim=-1).type('torch.FloatTensor')\n",
    "    pelvis_local = torch.matmul(transformation_mat_inv, homo_pelvis.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "    mocap[\"poses\"] = torch.cat((pelvis_local[:, :, :-1], mocap[\"angles\"]), dim=1).type('torch.FloatTensor')\n",
    "\n",
    "    \n",
    "\n",
    "    torch.save(mocap | contact, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s001: 100%|██████████| 54/54 [00:09<00:00,  5.71it/s]\n",
      "Processing: s002: 100%|██████████| 51/51 [00:09<00:00,  5.36it/s]\n",
      "Processing: s003: 100%|██████████| 54/54 [00:12<00:00,  4.44it/s]\n",
      "Processing: s004:   0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balletsmalljump\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s004:  67%|██████▋   | 28/42 [00:04<00:01,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taichi\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s004:  71%|███████▏  | 30/42 [00:04<00:01, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treearms\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s004: 100%|██████████| 42/42 [00:07<00:00,  5.61it/s]\n",
      "Processing: s005:  10%|█         | 5/49 [00:00<00:04,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s005:  51%|█████     | 25/49 [00:04<00:05,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidestretch\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s005:  78%|███████▊  | 38/49 [00:07<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n",
      "motion file not exists.. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: s005: 100%|██████████| 49/49 [00:08<00:00,  5.46it/s]\n",
      "Processing: s006: 100%|██████████| 57/57 [00:11<00:00,  4.93it/s]\n",
      "Processing: s007: 100%|██████████| 39/39 [00:07<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ALL participants!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "for participant in participants:\n",
    "    # print(\"Participant ID: \" + participant)\n",
    "    Datapath = \"../Data/\"\n",
    "    # mocap has npz format\n",
    "    inputMocap = Datapath + 'moshpp/' + participant\n",
    "    inputContact = Datapath + 'Force/' + participant\n",
    "\n",
    "\n",
    "    datasetPath = '../ProcessedData/'\n",
    "    outputPath = datasetPath + participants[participant] + '/preprocessed'\n",
    "    if not os.path.exists(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "\n",
    "    path = os.path.join(inputContact + '/*.npy')\n",
    "    forcefiles = glob.glob(path)\n",
    "\n",
    "    pbar = tqdm(forcefiles)\n",
    "    pbar.set_description(\"Processing: %s\"%participant)\n",
    "\n",
    "\n",
    "    for forcefile in pbar:\n",
    "        if system == 'Windows':\n",
    "            bar = '\\\\'\n",
    "        else:\n",
    "            bar = '/'\n",
    "        trial = os.path.splitext(forcefile)[0].split(bar)[-1]\n",
    "        motion = trial[14:-2]\n",
    "        if motiontype[motion] == 'ballet_high':\n",
    "            continue\n",
    "        if participant == 's001' and motion == 'idling':\n",
    "            continue\n",
    "        outputfile = outputPath + '/' + trial +'.pth'\n",
    "        if os.path.exists(outputfile):\n",
    "            # print(\"Skipping: \" + trial)\n",
    "            continue\n",
    "        else:\n",
    "            sourcemotion = inputMocap + '/' + trial + \"_stageii.npz\"\n",
    "            sourceforce = inputContact + '/' + trial + '.npy'\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(sourcemotion):\n",
    "                print(motion)\n",
    "                print(\"motion file not exists.. Skipping...\")\n",
    "            else:\n",
    "                parse_motion_force(sourcemotion, sourceforce, outputfile)\n",
    "\n",
    "print(\"Processed ALL participants!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GroundLinkSubmission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
